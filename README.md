# ğŸ”’ Credit Card Fraud Detection â€” ML Pipeline & API

<p align="center">
  <b>Real-time fraud detection</b> powered by <b>XGBoost</b> + <b>FastAPI</b><br>
  Data streamed directly from <b>Kaggle</b> â€” no local storage required
</p>

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Quick Start](#-quick-start)
- [API Reference](#-api-reference)
- [Docker Deployment](#-docker-deployment)
- [Configuration](#-configuration)
- [Model Performance](#-model-performance)
- [Technologies](#-technologies)

---

## ğŸ¯ Overview

This project is a professional, production-ready **machine learning pipeline** for detecting credit card fraud. It includes:

| Feature | Description |
|---------|-------------|
| **ğŸ—ƒï¸ Data Streaming** | Downloads Kaggle data on-the-fly without permanent storage |
| **ğŸ”§ Feature Engineering** | Age, distance, temporal features, amount transformations |
| **ğŸ¤– XGBoost Model** | Tuned for imbalanced classes with optimal threshold search |
| **âš¡ FastAPI** | REST API for real-time single & batch predictions |
| **ğŸ³ Docker** | Production-ready containers with docker-compose |
| **ğŸ§ª Tests** | Pytest-based API test suite |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kaggle     â”‚â”€â”€â”€â”€â–¶â”‚  Feature          â”‚â”€â”€â”€â”€â–¶â”‚   XGBoost    â”‚
â”‚   Dataset    â”‚     â”‚  Engineering      â”‚     â”‚   Training   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  Artifacts   â”‚
â”‚   Client     â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI         â”‚â”€â”€â”€â”€â–¶â”‚  .joblib     â”‚
â”‚   Request    â”‚     â”‚   /predict        â”‚â—€â”€â”€â”€â”€â”‚  (model,     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   scaler,    â”‚
                                              â”‚   encoders)  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
Detection-de-fraud/
â”œâ”€â”€ src/                      # Source package
â”‚   â”œâ”€â”€ __init__.py           # Package init
â”‚   â”œâ”€â”€ config.py             # Centralized configuration
â”‚   â”œâ”€â”€ data.py               # Kaggle data download (no local storage)
â”‚   â”œâ”€â”€ features.py           # Feature engineering pipeline
â”‚   â”œâ”€â”€ model.py              # Training, evaluation, serialization
â”‚   â”œâ”€â”€ schemas.py            # Pydantic request/response models
â”‚   â””â”€â”€ api.py                # FastAPI application
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py           # API test suite
â”œâ”€â”€ artifacts/                # Model artifacts (auto-generated)
â”œâ”€â”€ logs/                     # Training logs (auto-generated)
â”œâ”€â”€ train.py                  # ğŸš€ Training entry point
â”œâ”€â”€ run_api.py                # ğŸŒ API server entry point
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # Container image
â”œâ”€â”€ docker-compose.yml        # Multi-service deployment
â”œâ”€â”€ .env.example              # Environment variable template
â”œâ”€â”€ .gitignore                # Git ignore rules
â””â”€â”€ README.md                 # This file
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- **Python 3.10+**
- **Kaggle account** with API credentials

### 2. Setup Kaggle credentials

```bash
# Option A: Environment variables
export KAGGLE_USERNAME=your_username
export KAGGLE_KEY=your_api_key

# Option B: .env file
cp .env.example .env
# Edit .env with your credentials
```

> ğŸ’¡ Get your Kaggle API key at: https://www.kaggle.com/settings â†’ API â†’ Create New Token

### 3. Install dependencies

```bash
# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate      # Linux/Mac
# venv\Scripts\activate       # Windows

# Install packages
pip install -r requirements.txt
```

### 4. Train the model

```bash
python train.py
```

This will:
1. ğŸ“¥ Download data from Kaggle (temporary, cleaned up automatically)
2. ğŸ”§ Engineer features (age, distance, temporal, amount)
3. ğŸ¤– Train an XGBoost classifier with imbalance handling
4. ğŸ“Š Find optimal decision threshold (max F1)
5. ğŸ’¾ Save artifacts to `./artifacts/`

### 5. Launch the API

```bash
python run_api.py
```

The API will be available at:
- **Swagger UI** : http://localhost:8000/docs
- **ReDoc**      : http://localhost:8000/redoc
- **Health**     : http://localhost:8000/health

---

## ğŸ“¡ API Reference

### `GET /health` â€” Health Check

```bash
curl http://localhost:8000/health
```

```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0",
  "trained_at": "2025-02-19T...",
  "feature_count": 14,
  "metrics": {
    "roc_auc": 0.998,
    "f1_score": 0.82
  }
}
```

### `POST /predict` â€” Single Prediction

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "trans_date_trans_time": "2019-06-15 14:32:00",
    "cc_num": 4263982640269299,
    "merchant": "fraud_Rippin, Kub and Mann",
    "category": "grocery_pos",
    "amt": 1250.00,
    "first": "Jennifer",
    "last": "Banks",
    "gender": "F",
    "street": "561 Perry Cove",
    "city": "Jesup",
    "state": "GA",
    "zip": 31599,
    "lat": 31.5988,
    "long": -81.8826,
    "city_pop": 3495,
    "job": "Psychologist",
    "dob": "1988-03-09",
    "trans_num": "0b242abb623afc578575680df30655b9",
    "unix_time": 1371816865,
    "merch_lat": 36.011293,
    "merch_long": -82.048315
  }'
```

**Response:**
```json
{
  "is_fraud": true,
  "fraud_probability": 0.87432,
  "threshold_used": 0.42,
  "risk_level": "CRITICAL"
}
```

### `POST /predict/batch` â€” Batch Prediction

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{"transactions": [...]}'
```

**Response:**
```json
{
  "predictions": [...],
  "total": 50,
  "fraud_count": 3,
  "fraud_rate": 0.06
}
```

---

## ğŸ³ Docker Deployment

### Build & Train

```bash
# Build the image
docker-compose build

# Train the model (one-time)
docker-compose --profile train run train

# Start the API
docker-compose up api -d
```

### Check logs

```bash
docker-compose logs -f api
```

---

## âš™ï¸ Configuration

All configuration is managed through environment variables (`.env` file):

| Variable | Default | Description |
|----------|---------|-------------|
| `KAGGLE_USERNAME` | â€” | Kaggle API username |
| `KAGGLE_KEY` | â€” | Kaggle API key |
| `API_HOST` | `0.0.0.0` | API bind address |
| `API_PORT` | `8000` | API port |
| `MODEL_THRESHOLD` | `0.5` | Fallback decision threshold |

---

## ğŸ“Š Model Performance

The model is evaluated with metrics optimized for **imbalanced classification**:

| Metric | Focus |
|--------|-------|
| **PR AUC** | Primary metric â€” best for rare classes |
| **ROC AUC** | Overall discrimination |
| **F1 Score** | Balance of precision and recall |
| **Optimal threshold** | Automatically found to maximize F1 |

---

## ğŸ› ï¸ Technologies

| Category | Technology |
|----------|-----------|
| Language | Python 3.10+ |
| ML | XGBoost, scikit-learn |
| API | FastAPI, Uvicorn, Pydantic |
| Data | Pandas, NumPy, GeoPy |
| Deployment | Docker, docker-compose |
| Testing | Pytest, HTTPX |
| Logging | Loguru |

---

## ğŸ§ª Running Tests

```bash
pytest tests/ -v
```

---

## ğŸ“œ License

MIT License â€” Free for personal and commercial use.

---

<p align="center">
  Made with â¤ï¸ by <b>Bertrand</b>
</p>

